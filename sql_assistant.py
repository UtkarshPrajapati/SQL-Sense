import os
import logging
import json
from typing import List, Dict, Any, Tuple, Optional

import mysql.connector
from mysql.connector import FieldType
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.encoders import jsonable_encoder
from pydantic import BaseModel
import google.generativeai as genai
from dotenv import load_dotenv

# --- Configuration ---
load_dotenv() # Load environment variables from .env file

# Database Configuration (Update with your details)
MYSQL_HOST = os.getenv("MYSQL_HOST", "localhost")
MYSQL_USER = os.getenv("MYSQL_USER", "root")
MYSQL_PASSWORD = os.getenv("MYSQL_PASSWORD", "root")
MYSQL_DATABASE = os.getenv("MYSQL_DATABASE", "SQLLLM")

# Gemini API Configuration
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY not found in environment variables. Please set it in a .env file or environment.")

genai.configure(api_key=GEMINI_API_KEY)
# Use a model that supports function calling or is good at structured output if possible
# gemini-1.5-flash seems suitable for this kind of task. Adjust if needed.
GEMINI_MODEL_NAME = "gemini-2.0-flash"

# Logging Configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Database Interaction ---

# MODIFY get_db_connection to accept optional db_name
def get_db_connection(db_name: Optional[str] = None):
    """
    Establishes a connection to the MySQL server.
    Connects to a specific database if db_name is provided.
    """
    try:
        conn_params = {
            'host': MYSQL_HOST,
            'user': MYSQL_USER,
            'password': MYSQL_PASSWORD,
            'pool_name': "mypool", # Optional: Use connection pooling
            'pool_size': 5,       # Optional: Pool size
            'auth_plugin': 'mysql_native_password'
        }
        if db_name:
            conn_params['database'] = db_name

        conn = mysql.connector.connect(**conn_params)
        logger.info(f"DB connection established (Database: {db_name or 'None'})")
        return conn
    except mysql.connector.Error as err:
        logger.error(f"Database connection error (connecting to {db_name or 'server'}): {err}")
        # Don't raise HTTPException here directly, let caller handle None return or raise
        # raise HTTPException(status_code=500, detail=f"Database connection failed: {err}")
        return None # Return None on connection failure
def execute_sql_query(query: str) -> Tuple[Optional[List[Tuple]], Optional[List[str]], Optional[str], int, Optional[str]]:
    """
    Executes an SQL query against the database.

    Args:
        query: The SQL query string to execute.

    Returns:
        A tuple containing:
        - results: List of result tuples (or None).
        - column_names: List of column names (or None).
        - column_types_str: String describing column names and types (or None).
        - status_code: 1 (SELECT/SHOW success), 2 (Other DML/DDL success), 3 (Error).
        - error_message: Error details if status_code is 3.
    """
    logger.info(f"Executing Query: {query}")
    conn = None
    cursor = None
    results: Optional[List[Tuple]] = None # Initialize results
    column_names: Optional[List[str]] = None
    column_types_str: Optional[str] = None

    try:
        # Connect WITHOUT specifying a default database
        conn = get_db_connection(db_name=None)
        if not conn:
            # Handle connection failure
            error_message = "SQL Error: Failed to connect to the database server for query execution."
            logger.error(error_message)
            return None, None, None, 3, error_message

        cursor = conn.cursor(buffered=True)

        # --- SECURITY WARNING ---
        # Executing arbitrary SQL generated by an LLM or user input is a
        # significant security risk. In a production environment, you MUST:
        # 1. Sanitize and validate the query.
        # 2. Use parameterized queries where possible.
        # 3. Limit database user permissions (e.g., read-only access).
        # 4. Consider query allow-listing or blocking certain commands.
        # This example executes the query directly for simplicity, but DO NOT deploy like this.
        cursor.execute(query)

        query_lower = query.strip().lower()
        if query_lower.startswith("select") or query_lower.startswith("show"):
            results = cursor.fetchmany(100) # Limit results for display
            if cursor.description: # Check if description exists (it might not for some SHOW commands)
                column_names = [i[0] for i in cursor.description]
                # Ensure FieldType is imported or defined
                from mysql.connector.constants import FieldType
                col_dtypes = [[i[0], FieldType.get_info(i[1])] for i in cursor.description]
                column_types_str = 'Column : Dtype\n' + '\n'.join(f'{k}: {v}' for k, v in col_dtypes)
            else:
                column_names = ["Result"] # Default column name if description is unavailable
                column_types_str = "Column : Dtype\nResult: <unknown>"
                # Adjust results structure if needed based on the specific SHOW command
                # Check if results is not None and not empty before accessing results[0]
                if results and isinstance(results[0], (str, int, float, bytes)): # Added bytes type
                     results = [(r,) for r in results] # Wrap single values in tuples

            # conn is guaranteed to be non-None here due to the check above
            conn.commit() # Necessary even for SELECT with some configurations/engines
            # results is guaranteed to be a list (possibly empty) by fetchmany
            logger.info(f"Query executed successfully, fetched {len(results)} rows.")
            return results, column_names, column_types_str, 1, None
        else:
            # conn is guaranteed to be non-None here
            conn.commit()
            logger.info("Non-SELECT/SHOW query executed successfully.")
            return None, None, None, 2, None # Success for non-select queries

    except mysql.connector.Error as e:
        logger.error(f"SQL Error executing query '{query}': {e}")
        error_message = f"SQL Error: {e}"
        # Rollback changes if an error occurs during non-select queries
        if conn:
            try:
                conn.rollback()
            except mysql.connector.Error as rb_err:
                logger.error(f"Error during rollback: {rb_err}")
        return None, None, None, 3, error_message
    except Exception as e:
        logger.error(f"Unexpected error executing query '{query}': {e}", exc_info=True)
        error_message = f"Unexpected Error: {e}"
        # Rollback changes if an unexpected error occurs
        if conn:
             try:
                 conn.rollback()
             except mysql.connector.Error as rb_err:
                 logger.error(f"Error during rollback: {rb_err}")
        return None, None, None, 3, error_message
    finally:
        if cursor:
            cursor.close()
        # Check conn exists and is connected before closing
        if conn and conn.is_connected():
            conn.close()
            logger.info("DB connection closed.")


# REWRITE fetch_all_tables_and_columns to fetch from multiple databases
def fetch_all_tables_and_columns() -> Dict[str, Dict[str, List[str]]]:
    """
    Fetches all non-system databases, their tables, and columns.
    Returns: Dict[db_name, Dict[table_name, List[column_name]]]
    """
    schema_info: Dict[str, Dict[str, List[str]]] = {}
    conn = None
    cursor = None
    # Exclude system databases
    system_databases = {'information_schema', 'mysql', 'performance_schema', 'sys'}

    try:
        # Connect without specifying a database
        conn = get_db_connection(db_name=None)
        if not conn:
             logger.error("Failed to get DB connection for schema fetching.")
             return {"error": {"schema": ["Failed to connect to the database server."]}}

        cursor = conn.cursor()

        # Get all databases
        cursor.execute("SHOW DATABASES;")
        databases = [row[0] for row in cursor.fetchall() if row[0] not in system_databases]

        if not databases:
            logger.warning("No user databases found.")
            return {} # Return empty if no relevant databases

        # Get tables and columns for each relevant database
        for db_name in databases:
            schema_info[db_name] = {}
            try:
                cursor.execute(f"SHOW TABLES FROM `{db_name}`;")
                tables = [row[0] for row in cursor.fetchall()]

                for table_name in tables:
                    try:
                        cursor.execute(f"SHOW COLUMNS FROM `{db_name}`.`{table_name}`;")
                        columns = [column[0] for column in cursor.fetchall()]
                        schema_info[db_name][table_name] = columns
                    except mysql.connector.Error as e:
                        logger.warning(f"Could not fetch columns for table {db_name}.{table_name}: {e}")
                        schema_info[db_name][table_name] = [f"Error fetching columns: {e}"]

            except mysql.connector.Error as e:
                 logger.warning(f"Could not fetch tables for database {db_name}: {e}")
                 # Add an error placeholder for the database if tables couldn't be listed
                 schema_info[db_name] = {"error": [f"Error fetching tables: {e}"]}

        logger.info(f"Fetched schema for {len(databases)} databases.")
        return schema_info

    except mysql.connector.Error as e:
        logger.error(f"SQL Error fetching database list: {e}")
        return {"error": {"schema": [f"SQL Error fetching databases: {e}"]}} # Indicate error in schema structure
    except Exception as e:
        logger.error(f"Error fetching schema: {e}", exc_info=True)
        return {"error": {"schema": [f"Unexpected error fetching schema: {str(e)}"]}}
    finally:
        if cursor:
            cursor.close()
        if conn and conn.is_connected():
            conn.close()

# --- Gemini API Interaction ---

# MODIFY schema_string generation in generate_sql_with_gemini
def generate_sql_with_gemini(user_query: str, schema: Dict[str, Dict[str, List[str]]]) -> Optional[str]:
    """Generates an SQL query using the Gemini API based on user input and multi-DB schema."""
    schema_string = ""
    if not schema or "error" in schema: # Check for top-level error
         schema_string = "Could not fetch schema. Please ensure database connection is correct."
    else:
        for db_name, tables in schema.items():
            schema_string += f"\nDatabase: `{db_name}`\n"
            if isinstance(tables, dict): # Check if it's a dictionary of tables or an error list
                if not tables:
                     schema_string += "  (No tables found or accessible)\n"
                elif "error" in tables:
                     schema_string += f"  Error fetching tables: {tables['error']}\n"
                else:
                    for table_name, columns in tables.items():
                        col_string = ', '.join([f"`{c}`" for c in columns])
                        schema_string += f"  - Table: `{table_name}`: Columns: {col_string}\n"
            else:
                 # Handle case where schema[db_name] might be an error list itself (though unlikely with current fetch logic)
                 schema_string += f"  Error retrieving table details for this database.\n"


    prompt = f"""You are an expert SQL assistant. Given the following database schema across potentially multiple databases and a user question, generate the most appropriate SQL query to answer the question.

Database Schema:
{schema_string}

User Question: "{user_query}"

Instructions:
- Analyze the user question and the schema carefully.
- If querying a table, use the fully qualified name (e.g., `database_name`.`table_name`) unless the query context makes the database obvious or only one database exists. Prefer qualified names for clarity.
- Generate **only** the SQL query.
- Do not include any explanations, introductory text, backticks (```sql), or markdown formatting.
- Ensure the query is syntactically correct for MySQL.
- If the question cannot be answered with the given schema or is ambiguous, respond with "Error: Cannot answer question with available schema."

SQL Query:"""

    # --- rest of the function remains the same ---
    try:
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        response = model.generate_content(prompt)

        # Clean up potential markdown formatting just in case
        sql_query = response.text.strip()
        if sql_query.startswith("```sql"):
            sql_query = sql_query[6:]
        if sql_query.endswith("```"):
            sql_query = sql_query[:-3]
        sql_query = sql_query.strip() # Remove leading/trailing whitespace

        logger.info(f"Gemini generated SQL: {sql_query}")
        if sql_query.lower().startswith("error:"):
             logger.warning(f"Gemini indicated an error: {sql_query}")
             # Return the error message from Gemini
             return sql_query # Return the error string itself

        # Basic validation (prevent obviously non-SQL responses)
        # Allow for USE statement as well
        if not any(kw in sql_query.lower() for kw in ["select", "insert", "update", "delete", "show", "create", "alter", "drop", "use"]):
             logger.warning(f"Generated text doesn't look like SQL: {sql_query}")
             return "Error: Generated text does not appear to be a valid SQL query." # Return an error string

        return sql_query

    except Exception as e:
        logger.error(f"Error calling Gemini API for SQL generation: {e}", exc_info=True)
        return "Error: Failed to communicate with the AI model for SQL generation." # Return an error string

def get_insights_with_gemini(original_query: str, sql_query: str, results: List[Tuple], columns: List[str], col_types: str) -> str:
    """Generates insights on the data using the Gemini API."""
    if not results:
        return "No results to analyze."

    # Limit results sent to Gemini to avoid exceeding token limits
    results_preview = json.dumps(results[:20], indent=2, default=str) # Send first 20 rows as JSON

    prompt = f"""You are a data analyst assistant. A user asked the following question:
"{original_query}"

The following SQL query was executed to fetch data:
```sql
{sql_query}
```

The query returned the following data (showing up to 20 rows):
Columns and Types:
{col_types}

Results (JSON format):
{results_preview}

Instructions:
- Provide concise, insightful observations based *only* on the provided data sample.
- Do not invent data or make assumptions beyond what's shown.
- Suggest 1-2 potential follow-up questions or SQL queries the user might be interested in, based on these results and the original question.
- Format your response clearly using Markdown. Start with "### Data Insights" and then "### Suggested Follow-up".

Analysis:"""

    try:
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        response = model.generate_content(prompt)
        logger.info("Gemini generated insights.")
        return response.text
    except Exception as e:
        logger.error(f"Error calling Gemini API for insights: {e}", exc_info=True)
        return "Error generating insights from the AI model."

# --- FastAPI Application ---

app = FastAPI(title="SQL Assistant with Gemini")

# Mount static files (for CSS, JS if needed later)
# app.mount("/static", StaticFiles(directory="static"), name="static")

# Setup Jinja2 templates
templates = Jinja2Templates(directory=".") # Expect index.html in the same directory

class ChatRequest(BaseModel):
    message: str

@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    """Serves the main HTML page."""
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/schema", response_class=JSONResponse)
async def get_schema():
    """API endpoint to fetch the current database schema."""
    schema = fetch_all_tables_and_columns()
    if "error" in schema:
         # Return a specific error status if schema fetching failed critically
         # For now, returning 200 but with error content
         return JSONResponse(content={"schema": schema}, status_code=200)
    return JSONResponse(content={"schema": schema})


@app.post("/chat", response_class=JSONResponse)
async def handle_chat(chat_request: ChatRequest):
    """Handles user messages, interacts with DB and Gemini."""
    user_message = chat_request.message.strip()
    response_data: Dict[str, Any] = {"type": "error", "content": "An unexpected error occurred."}

    try:
        if user_message.lower().startswith("/run "):
            # Direct SQL execution
            query_to_run = user_message[5:].strip() # Get query after "/run "
            if not query_to_run:
                response_data = {"type": "error", "content": "No query provided after /run command."}
                return JSONResponse(content=response_data)

            logger.info(f"Executing direct query: {query_to_run}")
            results, columns, col_types, status, db_error = execute_sql_query(query_to_run)

            if status == 3: # SQL Error
                response_data = {"type": "error", "content": db_error or "Query execution failed."}
            elif status == 2: # DML/DDL Success
                response_data = {"type": "info", "content": f"Query executed successfully:\n```sql\n{query_to_run}\n```"}
            elif status == 1: # SELECT/SHOW Success
                insights = ""
                if results and columns and col_types:
                    # Get insights for SELECT/SHOW results
                    insights = get_insights_with_gemini(
                        original_query=f"Direct execution: {query_to_run}", # Provide context
                        sql_query=query_to_run,
                        results=results,
                        columns=columns,
                        col_types=col_types
                    )
                response_data = {
                    "type": "result",
                    "query": query_to_run,
                    "columns": columns,
                    "results": results,
                    "insights": insights
                }
            else: # Should not happen, but handle defensively
                 response_data = {"type": "error", "content": "Unknown query execution status."}

        else:
            # Natural language query -> Generate SQL -> Execute -> Get Insights
            logger.info(f"Processing natural language query: {user_message}")
            schema = fetch_all_tables_and_columns()
            if "error" in schema:
                 # Let user know schema couldn't be fetched
                 response_data = {"type": "error", "content": f"Could not fetch database schema to process your request. Error: {schema['error']}"}
                 return JSONResponse(content=response_data)

            generated_sql = generate_sql_with_gemini(user_message, schema)

            if not generated_sql:
                response_data = {"type": "error", "content": "The AI model could not generate an SQL query for your request, or indicated an error. Please try rephrasing."}
                return JSONResponse(content=response_data)

            # Check if Gemini refused to answer
            if generated_sql.lower().startswith("error:"):
                 response_data = {"type": "error", "content": generated_sql}
                 return JSONResponse(content=response_data)


            # Execute the generated SQL
            results, columns, col_types, status, db_error = execute_sql_query(generated_sql)

            if status == 3: # SQL Error
                # Maybe try generating SQL again? Or just report error. Reporting for now.
                response_data = {
                    "type": "error",
                    "content": f"Generated SQL failed to execute:\n```sql\n{generated_sql}\n```\nError: {db_error or 'Unknown SQL execution error.'}"
                 }
            elif status == 2: # DML/DDL Success
                response_data = {
                    "type": "info",
                    "content": f"Successfully executed generated query:\n```sql\n{generated_sql}\n```"
                }
            elif status == 1: # SELECT/SHOW Success
                insights = ""
                if results and columns and col_types:
                    insights = get_insights_with_gemini(
                        original_query=user_message,
                        sql_query=generated_sql,
                        results=results,
                        columns=columns,
                        col_types=col_types
                    )
                response_data = {
                    "type": "result",
                    "query": generated_sql,
                    "columns": columns,
                    "results": results,
                    "insights": insights
                }
            else: # Should not happen
                 response_data = {"type": "error", "content": "Unknown query execution status after generation."}

        return JSONResponse(content=jsonable_encoder(response_data))

    except HTTPException as http_exc:
        logger.error(f"HTTP Exception: {http_exc.detail}")
        # Re-raise HTTPException to let FastAPI handle it
        raise http_exc
    except Exception as e:
        logger.critical(f"Unhandled error in /chat endpoint: {e}", exc_info=True)
        # Return a generic server error response
        response_data = {"type": "error", "content": f"An internal server error occurred: {e}"}
        return JSONResponse(content=response_data, status_code=500)


# --- Main Execution ---
if __name__ == "__main__":
    import uvicorn
    logger.info("Starting SQL Assistant server...")
    # Make sure GEMINI_API_KEY is set before starting
    if not GEMINI_API_KEY:
         logger.critical("FATAL: GEMINI_API_KEY is not set. Exiting.")
    else:
        # Use port 8012 as in the original setup
        uvicorn.run(app, host="0.0.0.0", port=8012)